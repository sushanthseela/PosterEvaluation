{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\susha\\Desktop\\FontSizeandStyleEvaluation\\myenv\\lib\\site-packages\\ultralytics\\nn\\tasks.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(attempt_download(weight), map_location='cpu')  # load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as poster_evaluation_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import os\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import joblib\n",
    "\n",
    "# Expanded list of unsuitable fonts\n",
    "UNSUITABLE_FONTS = [\n",
    "    \"Comic Sans\", \"Papyrus\", \"Brush Script\", \"Chalkduster\", \"Impact\", \"Stencil\", \n",
    "    \"Courier\", \"Lucida Handwriting\", \"Jokerman\", \"Edwardian Script\", \"Kristen ITC\", \n",
    "    \"Harlow Solid\", \"Snap ITC\", \"Curlz MT\", \"Vivaldi\", \"Giddyup Std\", \"Bradley Hand\", \n",
    "    \"Old English Text\", \"Wide Latin\", \"Showcard Gothic\", \"Playbill\", \"Cooper Black\", \n",
    "    \"Algerian\", \"Pristina\", \"Magneto\", \"Viner Hand ITC\", \"Mistral\", \"Forte\", \n",
    "    \"Ravie\", \"Jester\", \"Kunstler Script\", \"Onyx\", \"Elephant\", \"Blackadder ITC\", \n",
    "    \"Monotype Corsiva\", \"Bodoni MT Poster\", \"Gill Sans Ultra Bold\", \"Copperplate Gothic Bold\", \n",
    "    \"Copperplate Gothic Light\", \"Broadway\", \"Perpetua Titling MT\", \"Rockwell Extra Bold\", \n",
    "    \"Berlin Sans FB\", \"Engravers MT\", \"Castellar\", \"Zapfino\", \"Segoe Script\", \n",
    "    \"Lucida Calligraphy\", \"Freestyle Script\", \"Stencil Std\", \"Garamond Bold\", \n",
    "    \"Baskerville Old Face\", \"Bookman Old Style\"\n",
    "]\n",
    "\n",
    "ACCESSIBLE_FONT_SIZE = 14  # Minimum size in points for accessibility\n",
    "\n",
    "# Load YOLO model for text detection\n",
    "def load_yolo_model():\n",
    "    return YOLO(\"yolov8n.pt\")\n",
    "\n",
    "model = load_yolo_model()\n",
    "\n",
    "# Function to calculate font size from bounding box height (approximate)\n",
    "def calculate_font_size(bounding_box_height):\n",
    "    scale_factor = 0.75  # Adjust scale factor to map pixel height to points\n",
    "    return bounding_box_height * scale_factor\n",
    "\n",
    "# Function to evaluate font size compliance (14pt or above is accessible)\n",
    "def is_accessible_font_size(detected_font_size):\n",
    "    return detected_font_size >= ACCESSIBLE_FONT_SIZE\n",
    "\n",
    "# Function to evaluate font style compliance\n",
    "def is_accessible_font_style(text_image):\n",
    "    ocr_result = pytesseract.image_to_string(text_image, config='--psm 6')\n",
    "    # Check if any unsuitable font is detected\n",
    "    return not any(font in ocr_result for font in UNSUITABLE_FONTS)\n",
    "\n",
    "# Process a single poster for font size and style compliance\n",
    "def process_poster(poster_path, model):\n",
    "    print(f\"Processing poster: {poster_path}\")\n",
    "    image = cv2.imread(poster_path)\n",
    "    if image is None:\n",
    "        print(\"Failed to load image.\")\n",
    "        return 0, 0\n",
    "\n",
    "    results = model(poster_path)\n",
    "    font_size_accessible_count = 0\n",
    "    font_style_accessible_count = 0\n",
    "    text_regions_count = 0\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result[:, :4]  # Extract x1, y1, x2, y2 from the tensor\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            text_region = image[y1:y2, x1:x2]  # Crop text region\n",
    "\n",
    "            # Calculate and evaluate font size\n",
    "            detected_font_size = calculate_font_size(y2 - y1)\n",
    "            if is_accessible_font_size(detected_font_size):\n",
    "                font_size_accessible_count += 1\n",
    "\n",
    "            # Evaluate font style\n",
    "            if is_accessible_font_style(text_region):\n",
    "                font_style_accessible_count += 1\n",
    "\n",
    "            text_regions_count += 1\n",
    "\n",
    "    # Determine majority for font size and style\n",
    "    font_size_score = 100 if font_size_accessible_count > text_regions_count / 2 else 0\n",
    "    font_style_score = 100 if font_style_accessible_count > text_regions_count / 2 else 0\n",
    "\n",
    "    print(f\"Font Size Score: {font_size_score}, Font Style Score: {font_style_score}\")\n",
    "    return font_size_score, font_style_score\n",
    "\n",
    "# Save the model and process function\n",
    "def save_joblib_model():\n",
    "    joblib.dump((model, process_poster), \"poster_evaluation_model.joblib\")\n",
    "    print(\"Model saved as poster_evaluation_model.joblib\")\n",
    "\n",
    "# Load the model and process function\n",
    "def load_joblib_model():\n",
    "    loaded_model, loaded_process_function = joblib.load(\"poster_evaluation_model.joblib\")\n",
    "    return loaded_model, loaded_process_function\n",
    "\n",
    "# Function to evaluate a single uploaded poster\n",
    "def evaluate_uploaded_poster(poster_path):\n",
    "    loaded_model, loaded_process_function = load_joblib_model()\n",
    "    font_size_score, font_style_score = loaded_process_function(poster_path, loaded_model)\n",
    "    print(f\"Poster: {poster_path}, Font Size Score: {font_size_score}%, Font Style Score: {font_style_score}%\")\n",
    "\n",
    "# Save the model for the first time\n",
    "save_joblib_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poster: C:\\Users\\susha\\Desktop\\FontSizeandStyleEvaluation\\Posters\\1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.0  Python-3.10.5 torch-2.5.0+cpu CPU\n",
      "Fusing layers... \n",
      "YOLOv8n summary: 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "image 1/1 C:\\Users\\susha\\Desktop\\FontSizeandStyleEvaluation\\Posters\\1.png: 448x640 1 book, 211.8ms\n",
      "Speed: 0.0ms pre-process, 211.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Font Size Score: 100, Font Style Score: 100\n",
      "Poster: C:\\Users\\susha\\Desktop\\FontSizeandStyleEvaluation\\Posters\\1.png, Font Size Score: 100%, Font Style Score: 100%\n"
     ]
    }
   ],
   "source": [
    "evaluate_uploaded_poster(\"C:\\\\Users\\\\susha\\\\Desktop\\\\FontSizeandStyleEvaluation\\\\Posters\\\\1.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
